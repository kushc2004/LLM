{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvZVXdoMSHfOBjsTV5u/LS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushc2004/LLM/blob/main/Manager.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxnPmpN_4z4u",
        "outputId": "6624864d-36c4-4e50-cc4d-f342254cdc3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kushc2004/LLM.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppsej0-3C8D1",
        "outputId": "6ac131a1-cd7d-4c1c-98fe-5ea26467e2d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LLM' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AGENT\n",
        "from typing import Dict, Optional, List, Tuple\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from accelerate import init_empty_weights, infer_auto_device_map, dispatch_model\n",
        "import torch\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, name, description, model_name, **kwargs):\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.system_prompt = \"You're a helpful assistant.\"\n",
        "        self.kwargs = kwargs\n",
        "        self.model_name = model_name\n",
        "\n",
        "        # Load the tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "\n",
        "        # Initialize the model with empty weights and use `init_empty_weights`\n",
        "        with init_empty_weights():\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(self.model_name, low_cpu_mem_usage=True)\n",
        "\n",
        "        # Infer the device map\n",
        "        device_map = infer_auto_device_map(self.model, max_memory={0: \"12GiB\", \"cpu\": \"30GiB\"})\n",
        "\n",
        "        # Dispatch the model to the appropriate devices\n",
        "        self.model = dispatch_model(self.model, device_map=device_map)\n",
        "\n",
        "    def llm_call(\n",
        "        self,\n",
        "        prompt: Optional[str] = None,\n",
        "        messages: Optional[List] = None,\n",
        "        seed: int = 10,\n",
        "    ) -> str:\n",
        "        # Ensure exactly one of prompt or messages is provided\n",
        "        assert (prompt is None) != (messages is None)\n",
        "\n",
        "        # Ensure if messages is provided, it is a list of dicts with role and content\n",
        "        if messages is not None:\n",
        "            assert isinstance(messages, list)\n",
        "            for message in messages:\n",
        "                assert isinstance(message, dict)\n",
        "                assert \"role\" in message\n",
        "                assert \"content\" in message\n",
        "\n",
        "        if prompt is not None:\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ]\n",
        "\n",
        "        # Concatenate messages into a single prompt\n",
        "        full_prompt = \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in messages])\n",
        "\n",
        "        # Tokenize the input\n",
        "        inputs = self.tokenizer(full_prompt, return_tensors=\"pt\")\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(**inputs, max_length=200, do_sample=True, top_p=0.95, top_k=50, temperature=0.7)\n",
        "\n",
        "        # Decode the response\n",
        "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        return response\n",
        "\n",
        "    def generate_reply(\n",
        "        self,\n",
        "        task: str,\n",
        "        state: Dict,\n",
        "        sender: \"Agent1\",\n",
        "    ) -> Tuple[str, Dict]:\n",
        "        return (\n",
        "            \"This is a reply from the agent. REPLY NOT IMPLEMENTED! Terminate the whole process!\",\n",
        "            state,\n",
        "        )\n",
        "\n"
      ],
      "metadata": {
        "id": "5XzrMZ1GDTmX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MANAGER\n",
        "from typing import Dict, Tuple\n",
        "import json\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
        "import torch\n",
        "\n",
        "class GroupChatManager(Agent):\n",
        "    def __init__(\n",
        "        self, model_name: str, agents: List[Agent], max_rounds: int = 12, **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            name=\"GroupChatManager\",\n",
        "            description=\"This is a manager agent that chooses which agent to work on the problem next and organizes the conversation within its team.\",\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        self.agents = agents\n",
        "        self.conversation_state = {\n",
        "            \"round\": 0,\n",
        "        }\n",
        "        self.max_rounds = max_rounds\n",
        "        self.history = []\n",
        "        self.prompt_template = \"\"\"\n",
        "\n",
        "You're a manager in a team of optimization experts. The goal of the team is to solve an optimization problem. Your task is to choose the next expert to work on the problem based on the current situation.\n",
        "- The user has already given us the problem description, the objective function, and the parameters. Only call the user proxy if there is a problem or something ambiguous or missing.\n",
        "\n",
        "Here's the list of agents in your team:\n",
        "-----\n",
        "{agents}\n",
        "-----\n",
        "\n",
        "And here's the history of the conversation so far:\n",
        "-----\n",
        "{history}\n",
        "-----\n",
        "\n",
        "\n",
        "Considering the history, if you think the problem is solved, type DONE. Otherwise, generate a json file with the following format:\n",
        "{{\n",
        "    \"agent_name\": \"Name of the agent you want to call next\",\n",
        "    \"task\": \"The task you want the agent to carry out\"\n",
        "}}\n",
        "\n",
        "to identify the next agent to work on the problem, and also the task it has to carry out.\n",
        "- If there is a runtime error, ask the the programmer agent to fix it.\n",
        "- Only generate the json file, and don't generate any other text.\n",
        "- If the latest message in history says that the code is fixed, ask the evaluator agent to evaluate the code!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        # Load the Llama model and tokenizer\n",
        "        self.tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
        "        self.model = LlamaForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "    def llm_call(self, prompt: str, seed: int) -> str:\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "        outputs = self.model.generate(**inputs, max_length=512)\n",
        "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return response\n",
        "\n",
        "    def solve(self, state: Dict) -> Tuple[str, Dict]:\n",
        "        self.history = []\n",
        "\n",
        "        while True:\n",
        "            if self.conversation_state[\"round\"] >= self.max_rounds:\n",
        "                return \"The problem is not solved.\", state\n",
        "\n",
        "            print(\"=\" * 20)\n",
        "            print(\"=\" * 20)\n",
        "            print(\"Round\", self.conversation_state[\"round\"])\n",
        "\n",
        "            agents_list = \"\".join(\n",
        "                [\n",
        "                    \"-\" + agent.name + \": \" + agent.description + \"\\n\"\n",
        "                    for agent in self.agents\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            prompt = self.prompt_template.format(\n",
        "                agents=agents_list,\n",
        "                history=\"\\n\".join([json.dumps(item[0]) for item in self.history]),\n",
        "            )\n",
        "\n",
        "            cnt = 3\n",
        "            while True and cnt > 0:\n",
        "                try:\n",
        "                    response = self.llm_call(prompt=prompt, seed=cnt)\n",
        "\n",
        "                    decision = response.strip()\n",
        "                    if \"```json\" in decision:\n",
        "                        decision = decision.split(\"```json\")[1].split(\"```\")[0]\n",
        "                    decision = decision.replace(\"\\\\\", \"\")\n",
        "\n",
        "                    if decision == \"DONE\":\n",
        "                        print(\"DONE\")\n",
        "                        return \"The problem is solved.\", state\n",
        "                    decision = json.loads(decision)\n",
        "                    break\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(response)\n",
        "                    print(e)\n",
        "                    cnt -= 1\n",
        "\n",
        "                    print(\"Invalid decision. Trying again ...\")\n",
        "                    if cnt == 0:\n",
        "                        import traceback\n",
        "\n",
        "                        err = traceback.format_exc()\n",
        "                        print(err)\n",
        "\n",
        "            print(\n",
        "                \"---- History:\\n\",\n",
        "                \"\\n\".join([json.dumps(item[0]) for item in self.history]),\n",
        "            )\n",
        "\n",
        "            print(f\"\\n---- Decision:||{decision}||\\n\")\n",
        "\n",
        "            if not decision[\"agent_name\"] in [agent.name for agent in self.agents]:\n",
        "                raise ValueError(\n",
        "                    f\"Decision {decision} is not a valid agent name. Please choose from {self.agents}\"\n",
        "                )\n",
        "            else:\n",
        "                agent = [\n",
        "                    agent\n",
        "                    for agent in self.agents\n",
        "                    if agent.name == decision[\"agent_name\"]\n",
        "                ][0]\n",
        "\n",
        "                message, new_state = agent.generate_reply(\n",
        "                    task=decision[\"task\"],\n",
        "                    state=state,\n",
        "                    sender=self,\n",
        "                )\n",
        "\n",
        "                with open(\n",
        "                    f\"{state['log_folder']}/log_{self.conversation_state['round']}.json\",\n",
        "                    \"w\",\n",
        "                ) as f:\n",
        "                    json.dump(state, f, indent=4)\n",
        "\n",
        "                state = new_state\n",
        "\n",
        "                decision[\"result\"] = message\n",
        "                self.history.append((decision, state))\n",
        "\n",
        "                with open(state[\"log_folder\"] + \"/selection_log.json\", \"w\") as f:\n",
        "                    json.dump([d for (d, s) in self.history], f, indent=4)\n",
        "\n",
        "                if \"code\" in state:\n",
        "                    with open(state[\"log_folder\"] + \"/code.py\", \"w\") as f:\n",
        "                        f.write(state[\"code\"])\n",
        "\n",
        "                self.conversation_state[\"round\"] += 1"
      ],
      "metadata": {
        "id": "_9tXRa1u-Gqz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MANAGER EXAMPLE\n",
        "# First, let's define the necessary classes from agent.py and manager.py\n",
        "from typing import Dict, Optional, List\n",
        "from unittest.mock import MagicMock\n",
        "import unittest\n",
        "import json\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, name, description, client, llm=\"gpt-3.5-turbo\", **kwargs):\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.client = client\n",
        "        self.system_prompt = \"You're a helpful assistant.\"\n",
        "        self.kwargs = kwargs\n",
        "        self.llm = llm\n",
        "\n",
        "    def llm_call(\n",
        "        self,\n",
        "        prompt: Optional[str] = None,\n",
        "        messages: Optional[List] = None,\n",
        "        seed: int = 10,\n",
        "    ) -> str:\n",
        "        model = self.llm\n",
        "        # make sure exactly one of prompt or messages is provided\n",
        "        assert (prompt is None) != (messages is None)\n",
        "        # make sure if messages is provided, it is a list of dicts with role and content\n",
        "        if messages is not None:\n",
        "            assert isinstance(messages, list)\n",
        "            for message in messages:\n",
        "                assert isinstance(message, dict)\n",
        "                assert \"role\" in message\n",
        "                assert \"content\" in message\n",
        "\n",
        "        if not prompt is None:\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ]\n",
        "\n",
        "        # Mocking the response for testing purposes\n",
        "        content = \"Mocked response content\"\n",
        "        return content\n",
        "\n",
        "    def generate_reply(\n",
        "        self,\n",
        "        task: str,\n",
        "        state: Dict,\n",
        "        sender: \"Agent\",\n",
        "    ) -> Tuple[str, Dict]:\n",
        "        return (\n",
        "            \"This is a reply from the agent. REPLY NOT IMPLEMENTED! Terminate the whole process!\",\n",
        "            state,\n",
        "        )\n",
        "\n",
        "class GroupChatManager(Agent):\n",
        "    def __init__(\n",
        "        self, client, agents: List[Agent], max_rounds: int = 12, **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            name=\"GroupChatManager\",\n",
        "            description=\"This is a manager agent that chooses which agent to work on the problem next and organizes the conversation within its team.\",\n",
        "            client=client,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        self.agents = agents\n",
        "        self.conversation_state = {\n",
        "            \"round\": 0,\n",
        "        }\n",
        "        self.max_rounds = max_rounds\n",
        "        self.history = []\n",
        "        self.prompt_template = \"\"\"\n",
        "\n",
        "You're a manager in a team of optimization experts. The goal of the team is to solve an optimization problem. Your task is to choose the next expert to work on the problem based on the current situation.\n",
        "- The user has already given us the problem description, the objective function, and the parameters. Only call the user proxy if there is a problem or something ambiguous or missing.\n",
        "\n",
        "Here's the list of agents in your team:\n",
        "-----\n",
        "{agents}\n",
        "-----\n",
        "\n",
        "And here's the history of the conversation so far:\n",
        "-----\n",
        "{history}\n",
        "-----\n",
        "\n",
        "\n",
        "Considering the history, if you think the problem is solved, type DONE. Otherwise, generate a json file with the following format:\n",
        "{{\n",
        "    \"agent_name\": \"Name of the agent you want to call next\",\n",
        "    \"task\": \"The task you want the agent to carry out\"\n",
        "}}\n",
        "\n",
        "to identify the next agent to work on the problem, and also the task it has to carry out.\n",
        "- If there is a runtime error, ask the the programmer agent to fix it.\n",
        "- Only generate the json file, and don't generate any other text.\n",
        "- If the latest message in history says that the code is fixed, ask the evaluator agent to evaluate the code!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    def solve(self, state: Dict) -> Tuple[str, Dict]:\n",
        "        self.history = []\n",
        "\n",
        "        while True:\n",
        "            if self.conversation_state[\"round\"] >= self.max_rounds:\n",
        "                return \"The problem is not solved.\", state\n",
        "\n",
        "            print(\"=\" * 20)\n",
        "            print(\"=\" * 20)\n",
        "            print(\"Round\", self.conversation_state[\"round\"])\n",
        "            # print(json.dumps(state, indent=4))\n",
        "\n",
        "            agents_list = \"\".join(\n",
        "                [\n",
        "                    \"-\" + agent.name + \": \" + agent.description + \"\\n\"\n",
        "                    for agent in self.agents\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            prompt = self.prompt_template.format(\n",
        "                agents=agents_list,\n",
        "                history=\"\\n\".join([json.dumps(item[0]) for item in self.history]),\n",
        "            )\n",
        "\n",
        "            cnt = 3\n",
        "            while True and cnt > 0:\n",
        "                try:\n",
        "                    response = self.llm_call(prompt=prompt, seed=cnt)\n",
        "\n",
        "                    decision = response.strip()\n",
        "                    if \"```json\" in decision:\n",
        "                        decision = decision.split(\"```json\")[1].split(\"```\")[0]\n",
        "                    decision = decision.replace(\"\\\\\", \"\")\n",
        "\n",
        "                    if decision == \"DONE\":\n",
        "                        print(\"DONE\")\n",
        "                        return \"The problem is solved.\", state\n",
        "                    decision = json.loads(decision)\n",
        "                    break\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(response)\n",
        "                    print(e)\n",
        "                    cnt -= 1\n",
        "\n",
        "                    print(\"Invalid decision. Trying again ...\")\n",
        "                    if cnt == 0:\n",
        "                        import traceback\n",
        "\n",
        "                        err = traceback.format_exc()\n",
        "                        print(err)\n",
        "\n",
        "            print(\n",
        "                \"---- History:\\n\",\n",
        "                \"\\n\".join([json.dumps(item[0]) for item in self.history]),\n",
        "            )\n",
        "\n",
        "            print(f\"\\n---- Decision:||{decision}||\\n\")\n",
        "\n",
        "            # wait for the user to press enter\n",
        "            # input()\n",
        "\n",
        "            if not decision[\"agent_name\"] in [agent.name for agent in self.agents]:\n",
        "                raise ValueError(\n",
        "                    f\"Decision {decision} is not a valid agent name. Please choose from {self.agents}\"\n",
        "                )\n",
        "            else:\n",
        "                agent = [\n",
        "                    agent\n",
        "                    for agent in self.agents\n",
        "                    if agent.name == decision[\"agent_name\"]\n",
        "                ][0]\n",
        "\n",
        "                message, new_state = agent.generate_reply(\n",
        "                    task=decision[\"task\"],\n",
        "                    state=state,\n",
        "                    sender=self,\n",
        "                )\n",
        "\n",
        "                with open(\n",
        "                    f\"/log_{self.conversation_state['round']}.json\",\n",
        "                    \"a+\",\n",
        "                ) as f:\n",
        "                    json.dump(state, f, indent=4)\n",
        "\n",
        "                state = new_state\n",
        "\n",
        "                decision[\"result\"] = message\n",
        "                self.history.append((decision, state))\n",
        "\n",
        "                with open( \"/selection_log.json\", \"a+\") as f:\n",
        "                    json.dump([d for (d, s) in self.history], f, indent=4)\n",
        "\n",
        "                if \"code\" in state:\n",
        "                    with open(\"/code.py\", \"a+\") as f:\n",
        "                        f.write(state[\"code\"])\n",
        "\n",
        "                self.conversation_state[\"round\"] += 1\n",
        "\n",
        "# Now, let's define the test case\n",
        "\n",
        "class TestGroupChatManager(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        # Create a mock client\n",
        "        mock_client = MagicMock()\n",
        "\n",
        "        # Create mock agents\n",
        "        self.formulator = Agent(name=\"Formulator\", description=\"Formulates problems\", client=mock_client)\n",
        "        self.programmer = Agent(name=\"Programmer\", description=\"Writes code\", client=mock_client)\n",
        "        self.evaluator = Agent(name=\"Evaluator\", description=\"Evaluates solutions\", client=mock_client)\n",
        "\n",
        "        # Initialize GroupChatManager with mock agents\n",
        "        self.manager = GroupChatManager(\n",
        "            client=mock_client,\n",
        "            agents=[self.formulator, self.programmer, self.evaluator],\n",
        "            max_rounds=3\n",
        "        )\n",
        "\n",
        "        # Mock state\n",
        "        self.state = {\n",
        "            \"background\": \"Test background\",\n",
        "            \"problem_type\": \"LP\",\n",
        "            \"parameters\": [],\n",
        "            \"constraint\": [],\n",
        "            \"variables\": [],\n",
        "            \"objective\": [],\n",
        "            \"solution_status\": None,\n",
        "            \"solver_output_status\": None,\n",
        "            \"error_message\": None,\n",
        "            \"obj_val\": None,\n",
        "            \"log_folder\": \"logs/test_log/\",\n",
        "            \"data_json_path\": \"data/test_data.json\",\n",
        "        }\n",
        "\n",
        "        def test_solve(self):\n",
        "            # Mock the llm_call method to return a sequence of valid decisions\n",
        "            self.manager.llm_call = MagicMock(side_effect=[\n",
        "                '{\"agent_name\": \"Formulator\", \"task\": \"Formulate the problem\"}',\n",
        "                '{\"agent_name\": \"Programmer\", \"task\": \"Write the code\"}',\n",
        "                '{\"agent_name\": \"Evaluator\", \"task\": \"Evaluate the solution\"}',\n",
        "                'DONE'\n",
        "            ])\n",
        "\n",
        "            # Run the solve method\n",
        "            result, state = self.manager.solve(self.state)\n",
        "\n",
        "            # Check the result\n",
        "            self.assertEqual(result, \"The problem is solved.\")\n",
        "            self.assertEqual(self.manager.conversation_state[\"round\"], 4)\n",
        "            self.formulator.generate_reply.assert_called_once()\n",
        "            self.programmer.generate_reply.assert_called_once()\n",
        "            self.evaluator.generate_reply.assert_called_once()\n",
        "            self.assertEqual(state, self.state)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGI9W9GEHhwO",
        "outputId": "12948515-d11b-4965-c497-e49a27db7b3e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 0 tests in 0.000s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I54T7PvnDF1",
        "outputId": "5926da13-fab9-49ab-953b-c0815bd0cda0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FORMULATOR\n",
        "from typing import Dict\n",
        "import json\n",
        "from transformers import pipeline\n",
        "\n",
        "fix_prompt_template = \"\"\"\n",
        "You are a mathematical formulator working with a team of optimization experts. The objective is to tackle a complex optimization problem, and your role is to fix a previously modelled {target}.\n",
        "\n",
        "Recall that the {target} you modelled was\n",
        "\n",
        "-----\n",
        "{constraint}\n",
        "-----\n",
        "\n",
        "and your formulation you provided was\n",
        "\n",
        "-----\n",
        "{formulation}\n",
        "-----\n",
        "\n",
        "The error message is\n",
        "\n",
        "-----\n",
        "{error}\n",
        "-----\n",
        "\n",
        "Here are the variables you have so far defined:\n",
        "\n",
        "-----\n",
        "{variables}\n",
        "-----\n",
        "\n",
        "Here are the parameters of the problem\n",
        "\n",
        "-----\n",
        "{parameters}\n",
        "-----\n",
        "\n",
        "Your task is carefully inspect the old {target} and fix it when you find it actually wrong.\n",
        "After fixing it modify the formulation. Please return the fixed JSON string for the formulation.\n",
        "\n",
        "The current JSON is\n",
        "\n",
        "-----\n",
        "{json}\n",
        "-----\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "You are an expert mathematical formulator and an optimization professor at a top university. Your task is to model {targetType} of the problem in the standard LP or MILP form.\n",
        "\n",
        "Here is a {targetType} we need you to model:\n",
        "-----\n",
        "{targetDescription}\n",
        "-----\n",
        "\n",
        "Here is some context on the problem:\n",
        "-----\n",
        "{background}\n",
        "-----\n",
        "\n",
        "Here is the list of available variables:\n",
        "-----\n",
        "{variables}\n",
        "-----\n",
        "\n",
        "And finally, here is list of input parameters:\n",
        "-----\n",
        "{parameters}\n",
        "-----\n",
        "\n",
        "First, take a deep breath and explain how we should define the {targetType}. Feel free to define new variables if you think it is necessary. Then, generate a json file accordingly with the following format (STICK TO THIS FORMAT!):\n",
        "\n",
        "\n",
        "{{\n",
        "    \"{targetType}\": {{\n",
        "      \"description\": \"The description of the {targetType}\",\n",
        "      \"formulation\": \"The LaTeX mathematical expression representing the formulation of the {targetType}\"\n",
        "    }},\n",
        "    \"auxiliary_constraints\": [\n",
        "        {{\n",
        "            \"description\": \"The description of the auxiliary constraint\",\n",
        "            \"formulation\": \"The LaTeX mathematical expression representing the formulation of the auxiliary constraint\"\n",
        "        }}\n",
        "    ]\n",
        "    \"new_variables\": [\n",
        "        {{\n",
        "            \"definition\": \"The definition of the variable\",\n",
        "            \"symbol\": \"The symbol for the variable\",\n",
        "            \"shape\": [ \"symbol1\", \"symbol2\", ... ]\n",
        "        }}\n",
        "    ],\n",
        "\n",
        "}}\n",
        "\n",
        "- Your formulation should be in LaTeX mathematical format (do not include the $ symbols).\n",
        "- Note that I'm going to use python json.loads() function to parse the json file, so please make sure the format is correct (don't add ',' before enclosing '}}' or ']' characters.\n",
        "- Generate the complete json file and don't omit anything.\n",
        "- Use '```json' and '```' to enclose the json file.\n",
        "- Important: You can not define new parameters. You can only define new variables.Use CamelCase and full words for new variable symbols, and do not include indices in the symbol (e.g. ItemsSold instead of itemsSold or items_sold or ItemsSold_i)\n",
        "- Use \\\\textup{{}} when writing variable and parameter names. For example (\\\\sum_{{i=1}}^{{N}} \\\\textup{{ItemsSold}}_{{i}} instead of \\\\sum_{{i=1}}^{{N}} ItemsSold_{{i}})\n",
        "- Use \\\\quad for spaces.\n",
        "- Use empty list ([]) if no new variables are defined.\n",
        "- Always use non-strict inequalities (e.g. \\\\leq instead of <), even if the constraint is strict.\n",
        "- Define auxiliary constraints when necessary. Set it to an empty list ([]) if no auxiliary constraints are needed. If new auxiliary constraints need new variables, add them to the \"new_variables\" list too.\n",
        "\n",
        "Take a deep breath and solve the problem step by step.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Formulator(Agent):\n",
        "    def __init__(self, client=None, **kwargs):\n",
        "        super().__init__(\n",
        "            name=\"Formulator\",\n",
        "            description=\"This is a mathematical formulator agent that is an expert in mathematical and optimization modeling and can define and modify variables, constraints, and objective functions. Does 3 things: 1) Defining constraints, variables, and objective functions, 2) Modifying constraints, variables, and objective functions, 3) Other things related to mathematical formulation. If the history is empty, start from this agent.\",\n",
        "            client=client,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.llm = pipeline('text-generation', model='huggingface/llama')\n",
        "\n",
        "    def _formulate(self, target_type: str, state):\n",
        "        for target in state[target_type]:\n",
        "            if target[\"status\"] == \"not_formulated\":\n",
        "                self._create_new_formulation(target, target_type, state)\n",
        "            elif target[\"status\"] == \"runtime_error\":\n",
        "                self._fix_available_formulation(target, target_type, state)\n",
        "            elif target[\"status\"] == \"formulated\":\n",
        "                continue\n",
        "            else:\n",
        "                error_msg = f\"Invalid status: {json.dumps(target, indent=4)}\"\n",
        "                raise RuntimeError(error_msg)\n",
        "\n",
        "        return\n",
        "\n",
        "    def _create_new_formulation(self, target, target_type: str, state):\n",
        "        print(f\"Formulating {target_type} ...\")\n",
        "        context = {}\n",
        "        context[target_type] = {}\n",
        "        prompt = prompt_template.format(\n",
        "            background=state[\"background\"],\n",
        "            targetType=target_type,\n",
        "            targetDescription=target[\"description\"],\n",
        "            variables=json.dumps(\n",
        "                [\n",
        "                    {\n",
        "                        \"definition\": v[\"definition\"],\n",
        "                        \"symbol\": v[\"symbol\"],\n",
        "                        \"shape\": v[\"shape\"],\n",
        "                    }\n",
        "                    for v in state[\"variables\"]\n",
        "                ],\n",
        "                indent=4,\n",
        "            ),\n",
        "            parameters=json.dumps(\n",
        "                [\n",
        "                    {\n",
        "                        \"definition\": p[\"definition\"],\n",
        "                        \"symbol\": p[\"symbol\"],\n",
        "                        \"shape\": p[\"shape\"],\n",
        "                    }\n",
        "                    for p in state[\"parameters\"]\n",
        "                ],\n",
        "                indent=4,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        cnt = 3\n",
        "        while cnt > 0:\n",
        "            cnt -= 1\n",
        "            try:\n",
        "                response = self.llm(prompt, max_length=1024, num_return_sequences=1)[0]['generated_text']\n",
        "                print(\"=\" * 10)\n",
        "                print(response)\n",
        "                print(\"=\" * 10)\n",
        "                output = response\n",
        "                # delete until the first '```json'\n",
        "                if \"```json\" in output:\n",
        "                    output = output[output.find(\"```json\") + 7 :]\n",
        "                    output = output[: output.rfind(\"```\")]\n",
        "\n",
        "                # go back until the last character is a }\n",
        "                while output[-1] != \"}\":\n",
        "                    output = output[:-1]\n",
        "\n",
        "                # go forward until the first character is a {\n",
        "                while output[0] != \"{\":\n",
        "                    output = output[1:]\n",
        "\n",
        "                # if there are '$' in the output, remove them\n",
        "                if \"$\" in output:\n",
        "                    output = output.replace(\"$\", \"\")\n",
        "\n",
        "                # find \"formulation\": \" in output\n",
        "                formulation_start = output.find('\"formulation\"')\n",
        "                # find \"new_variables\": \" in output\n",
        "                auxiliary_constraints_start = output.find('\"auxiliary_constraints\"')\n",
        "                # go back until you find a closed bracket\n",
        "                while output[auxiliary_constraints_start] != \"}\":\n",
        "                    auxiliary_constraints_start -= 1\n",
        "                while output[auxiliary_constraints_start] != '\"':\n",
        "                    auxiliary_constraints_start -= 1\n",
        "\n",
        "                # extract the formulation\n",
        "                formulation = output[\n",
        "                    formulation_start + 16 : auxiliary_constraints_start\n",
        "                ]\n",
        "                # remove it from the output\n",
        "                output = (\n",
        "                    output[: formulation_start + 16]\n",
        "                    + output[auxiliary_constraints_start:]\n",
        "                )\n",
        "\n",
        "                formulation = formulation.replace(\"\\\\\\\\\", \"\\\\\")\n",
        "                output = output.replace(\"\\\\\", \"\\\\\\\\\")\n",
        "                output = output.replace(\"\\\\\", \"\\\\\\\\\")\n",
        "                output = output.replace(\"\\\\\\\\quad\", \"\\\\\\\\\")\n",
        "\n",
        "                update = json.loads(output)\n",
        "                update[target_type][\"formulation\"] = formulation\n",
        "\n",
        "                # Extract related variables and parameters from the formulation\n",
        "                related_stuff = self.get_related_stuff(\n",
        "                    state, formulation, update[\"new_variables\"]\n",
        "                )\n",
        "                update[\"variables_mentioned\"] = related_stuff[\"variables_mentioned\"]\n",
        "                update[\"parameters_mentioned\"] = related_stuff[\"parameters_mentioned\"]\n",
        "\n",
        "                if not \"new_variables\" in update.keys():\n",
        "                    raise Exception(\"new_variables is not in the json file!\")\n",
        "                if not \"formulation\" in update[target_type].keys():\n",
        "                    raise Exception(\"formulation is not in the json file!\")\n",
        "                if not \"auxiliary_constraints\" in update.keys():\n",
        "                    update[\"auxiliary_constraints\"] = []\n",
        "\n",
        "                break\n",
        "            except Exception as e:\n",
        "                import traceback\n",
        "\n",
        "                print(traceback.format_exc())\n",
        "                print(\"=\" * 10)\n",
        "                print(e)\n",
        "                print(\"=\" * 10)\n",
        "                print(prompt)\n",
        "                print(\"=\" * 10)\n",
        "                print(response)\n",
        "                print(\"=\" * 10)\n",
        "                print(\n",
        "                    f\"Invalid json format in {target_type} formulation!\\n{e}\\n Try again ...\"\n",
        "                )\n",
        "\n",
        "        if cnt == 0:\n",
        "            raise Exception(\"Invalid json format!\")\n",
        "\n",
        "        all_variable_symbols = [variable[\"symbol\"] for variable in state[\"variables\"]]\n",
        "\n",
        "        for variable in update[\"new_variables\"]:\n",
        "            if variable[\"symbol\"] in all_variable_symbols:\n",
        "                # raise Exception(f\"Variable {variable['symbol']} already exists!\")\n",
        "                continue\n",
        "            else:\n",
        "                variable[\"status\"] = \"formulated\"\n",
        "                state[\"variables\"].append(variable)\n",
        "                if not variable[\"symbol\"] in update[\"variables_mentioned\"]:\n",
        "                    update[\"variables_mentioned\"].append(variable[\"symbol\"])\n",
        "\n",
        "        target[\"formulation\"] = update[target_type][\"formulation\"]\n",
        "        target[\"status\"] = \"formulated\"\n",
        "\n",
        "        target[\"related_variables\"] = update[\"variables_mentioned\"]\n",
        "        target[\"related_parameters\"] = update[\"parameters_mentioned\"]\n",
        "\n",
        "        # Add auxiliary constraints\n",
        "        if \"auxiliary_constraints\" in update.keys():\n",
        "            for constraint in update[\"auxiliary_constraints\"]:\n",
        "                constraint[\"status\"] = \"formulated\"\n",
        "\n",
        "                constraint[\"formulation\"] = (\n",
        "                    constraint[\"formulation\"]\n",
        "                    .replace(\"\\\\\\\\\", \"\\\\\")\n",
        "                    .replace(\"\\\\\\\\\", \"\\\\\")\n",
        "                )\n",
        "\n",
        "                # Extract related variables and parameters from the formulation\n",
        "                related_stuff = self.get_related_stuff(\n",
        "                    state, constraint[\"formulation\"], []\n",
        "                )\n",
        "                constraint[\"related_variables\"] = related_stuff[\"variables_mentioned\"]\n",
        "                constraint[\"related_parameters\"] = related_stuff[\"parameters_mentioned\"]\n",
        "\n",
        "                state[\"constraint\"].append(constraint)\n",
        "\n",
        "        print(f\"Formulation: {target['formulation']}\")\n",
        "        print(\"---\")\n",
        "        return\n",
        "\n",
        "    def _fix_available_formulation(self, target, target_type: str, state):\n",
        "        print(f\"Fixing {target_type} ...\")\n",
        "        context = {}\n",
        "        context[target_type] = {}\n",
        "        context[target_type][\"description\"] = target[\"description\"]\n",
        "\n",
        "        context[\"variables\"] = state[\"variables\"]\n",
        "        context[\"parameters\"] = state[\"parameters\"]\n",
        "        context[\"formulation\"] = target[\"formulation\"]\n",
        "        context[\"error\"] = state[\"error_message\"]\n",
        "\n",
        "        prompt = fix_prompt_template.format(\n",
        "            target=target_type,\n",
        "            constraint=json.dumps(context[target_type][\"description\"], indent=4),\n",
        "            variables=json.dumps(context[\"variables\"], indent=4),\n",
        "            parameters=json.dumps(context[\"parameters\"], indent=4),\n",
        "            formulation=json.dumps(context[\"formulation\"], indent=4),\n",
        "            json=json.dumps(target),\n",
        "            error=context[\"error\"],\n",
        "        )\n",
        "\n",
        "        cnt = 3\n",
        "        while cnt > 0:\n",
        "            cnt -= 1\n",
        "            try:\n",
        "                response = self.llm(prompt, max_length=1024, num_return_sequences=1)[0]['generated_text']\n",
        "                # delete until the first '```json'\n",
        "                output = response[response.find(\"```json\") + 7 :]\n",
        "                # delete until the last '```'\n",
        "                output = output[: output.rfind(\"```\")]\n",
        "\n",
        "                output = output.replace(\" \\\\\", \" \\\\\\\\\")\n",
        "                update = json.loads(output)\n",
        "\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                print(\n",
        "                    f\"Invalid json format in {target_type} formulation! Try again ...\"\n",
        "                )\n",
        "\n",
        "        if cnt == 0:\n",
        "            raise Exception(\"Invalid json format!\")\n",
        "\n",
        "        target[\"formulation\"] = update[\"formulation\"]\n",
        "        target[\"related_variables\"] = update[\"related_variables\"]\n",
        "        target[\"related_parameters\"] = update[\"related_parameters\"]\n",
        "        target[\"status\"] = \"formulated\"\n",
        "\n",
        "        return\n",
        "\n",
        "    def generate_reply(self, task: str, state: Dict, sender: Agent) -> (str, Dict):\n",
        "        # add some lines and characters around it to make the input interface nicer\n",
        "\n",
        "        print(\"- Formulator agent is called!\")\n",
        "        print()\n",
        "\n",
        "        self._formulate(\"constraint\", state)\n",
        "        self._formulate(\"objective\", state)\n",
        "\n",
        "        return \"Formulation Done! Now we can write the code.\", state\n",
        "\n",
        "    def get_related_stuff(self, state, formulation, new_variables):\n",
        "        ret = {}\n",
        "        ret[\"variables_mentioned\"] = []\n",
        "        ret[\"parameters_mentioned\"] = []\n",
        "\n",
        "        # find all symbols enclosed in \\textup{} in the formulation\n",
        "        symbols_mentioned = []\n",
        "        for i in range(len(formulation)):\n",
        "            if formulation[i : i + 8] == \"\\\\textup{\":\n",
        "                j = i + 8\n",
        "                while formulation[j] != \"}\":\n",
        "                    j += 1\n",
        "                symbols_mentioned.append(formulation[i + 8 : j])\n",
        "\n",
        "        all_parameter_symbols = [\n",
        "            parameter[\"symbol\"] for parameter in state[\"parameters\"]\n",
        "        ]\n",
        "        all_variable_symbols = [variable[\"symbol\"] for variable in state[\"variables\"]]\n",
        "        all_variable_symbols += [variable[\"symbol\"] for variable in new_variables]\n",
        "\n",
        "        # print(all_parameter_symbols)\n",
        "        # print(all_variable_symbols)\n",
        "\n",
        "        for symbol in symbols_mentioned:\n",
        "            if symbol in all_parameter_symbols:\n",
        "                ret[\"parameters_mentioned\"].append(symbol)\n",
        "            elif symbol in all_variable_symbols:\n",
        "                ret[\"variables_mentioned\"].append(symbol)\n",
        "            elif symbol.lower().strip() in [\n",
        "                \"min\",\n",
        "                \"max\",\n",
        "                \"subject to\",\n",
        "                \"s.t.\",\n",
        "                \"st\",\n",
        "                \"minimize\",\n",
        "                \"maximize\",\n",
        "                \"sum\",\n",
        "                \"for all\",\n",
        "                \"forall\",\n",
        "                \"such that\",\n",
        "                \"and\",\n",
        "                \"or\",\n",
        "                \"if\",\n",
        "                \"then\",\n",
        "                \"else\",\n",
        "                \"otherwise\",\n",
        "                \"for each\",\n",
        "                \"exists\",\n",
        "                \"foreach\",\n",
        "            ]:\n",
        "                continue\n",
        "            elif \" \" in symbol:\n",
        "                continue\n",
        "            else:\n",
        "                raise Exception(f\"Symbol {symbol} is not defined!\")\n",
        "\n",
        "        return ret"
      ],
      "metadata": {
        "id": "44QOMYPwnfP3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FORMULATOR EXAMPLE\n",
        "from typing import Dict\n",
        "\n",
        "import json\n",
        "import openai\n",
        "\n",
        "fix_prompt_template = \"\"\"\n",
        "You are a mathematical formulator working with a team of optimization experts. The objective is to tackle a complex optimization problem, and your role is to fix a previously modelled {target}.\n",
        "\n",
        "Recall that the {target} you modelled was\n",
        "\n",
        "-----\n",
        "{constraint}\n",
        "-----\n",
        "\n",
        "and your formulation you provided was\n",
        "\n",
        "-----\n",
        "{formulation}\n",
        "-----\n",
        "\n",
        "The error message is\n",
        "\n",
        "-----\n",
        "{error}\n",
        "-----\n",
        "\n",
        "Here are the variables you have so far defined:\n",
        "\n",
        "-----\n",
        "{variables}\n",
        "-----\n",
        "\n",
        "Here are the parameters of the problem\n",
        "\n",
        "-----\n",
        "{parameters}\n",
        "-----\n",
        "\n",
        "Your task is carefully inspect the old {target} and fix it when you find it actually wrong.\n",
        "After fixing it modify the formulation. Please return the fixed JSON string for the formulation.\n",
        "\n",
        "The current JSON is\n",
        "\n",
        "-----\n",
        "{json}\n",
        "-----\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "You are an expert mathematical formulator and an optimization professor at a top university. Your task is to model {targetType} of the problem in the standard LP or MILP form.\n",
        "\n",
        "Here is a {targetType} we need you to model:\n",
        "-----\n",
        "{targetDescription}\n",
        "-----\n",
        "\n",
        "Here is some context on the problem:\n",
        "-----\n",
        "{background}\n",
        "-----\n",
        "\n",
        "Here is the list of available variables:\n",
        "-----\n",
        "{variables}\n",
        "-----\n",
        "\n",
        "And finally, here is list of input parameters:\n",
        "-----\n",
        "{parameters}\n",
        "-----\n",
        "\n",
        "First, take a deep breath and explain how we should define the {targetType}. Feel free to define new variables if you think it is necessary. Then, generate a json file accordingly with the following format (STICK TO THIS FORMAT!):\n",
        "\n",
        "\n",
        "{{\n",
        "    \"{targetType}\": {{\n",
        "      \"description\": \"The description of the {targetType}\",\n",
        "      \"formulation\": \"The LaTeX mathematical expression representing the formulation of the {targetType}\"\n",
        "    }},\n",
        "    \"auxiliary_constraints\": [\n",
        "        {{\n",
        "            \"description\": \"The description of the auxiliary constraint\",\n",
        "            \"formulation\": \"The LaTeX mathematical expression representing the formulation of the auxiliary constraint\"\n",
        "        }}\n",
        "    ]\n",
        "    \"new_variables\": [\n",
        "        {{\n",
        "            \"definition\": \"The definition of the variable\",\n",
        "            \"symbol\": \"The symbol for the variable\",\n",
        "            \"shape\": [ \"symbol1\", \"symbol2\", ... ]\n",
        "        }}\n",
        "    ],\n",
        "\n",
        "}}\n",
        "\n",
        "- Your formulation should be in LaTeX mathematical format (do not include the $ symbols).\n",
        "- Note that I'm going to use python json.loads() function to parse the json file, so please make sure the format is correct (don't add ',' before enclosing '}}' or ']' characters.\n",
        "- Generate the complete json file and don't omit anything.\n",
        "- Use '```json' and '```' to enclose the json file.\n",
        "- Important: You can not define new parameters. You can only define new variables.Use CamelCase and full words for new variable symbols, and do not include indices in the symbol (e.g. ItemsSold instead of itemsSold or items_sold or ItemsSold_i)\n",
        "- Use \\\\textup{{}} when writing variable and parameter names. For example (\\\\sum_{{i=1}}^{{N}} \\\\textup{{ItemsSold}}_{{i}} instead of \\\\sum_{{i=1}}^{{N}} ItemsSold_{{i}})\n",
        "- Use \\\\quad for spaces.\n",
        "- Use empty list ([]) if no new variables are defined.\n",
        "- Always use non-strict inequalities (e.g. \\\\leq instead of <), even if the constraint is strict.\n",
        "- Define auxiliary constraints when necessary. Set it to an empty list ([]) if no auxiliary constraints are needed. If new auxiliary constraints need new variables, add them to the \"new_variables\" list too.\n",
        "\n",
        "Take a deep breath and solve the problem step by step.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Formulator(Agent):\n",
        "    def __init__(self, client: openai.Client, **kwargs):\n",
        "        super().__init__(\n",
        "            name=\"Formulator\",\n",
        "            description=\"This is a mathematical formulator agent that is an expert in mathematical and optimization modeling and can define and modify variables, constraints, and objective functions. Does 3 things: 1) Defining constraints, variables, and objective functions, 2) Modifying constraints, variables, and objective functions, 3) Other things related to mathematical formulation. If the history is empty, start from this agent.\",\n",
        "            client=client,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    def _formulate(self, target_type: str, state):\n",
        "        for target in state[target_type]:\n",
        "            if target[\"status\"] == \"not_formulated\":\n",
        "                self._create_new_formulation(target, target_type, state)\n",
        "            elif target[\"status\"] == \"runtime_error\":\n",
        "                self._fix_available_formulation(target, target_type, state)\n",
        "            elif target[\"status\"] == \"formulated\":\n",
        "                continue\n",
        "            else:\n",
        "                error_msg = f\"Invalid status: {json.dumps(target, indent=4)}\"\n",
        "                raise RuntimeError(error_msg)\n",
        "\n",
        "        return\n",
        "\n",
        "    def _create_new_formulation(self, target, target_type: str, state):\n",
        "        print(f\"Formulating {target_type} ...\")\n",
        "        context = {}\n",
        "        context[target_type] = {}\n",
        "        prompt = prompt_template.format(\n",
        "            background=state[\"background\"],\n",
        "            targetType=target_type,\n",
        "            targetDescription=target[\"description\"],\n",
        "            variables=json.dumps(\n",
        "                [\n",
        "                    {\n",
        "                        \"definition\": v[\"definition\"],\n",
        "                        \"symbol\": v[\"symbol\"],\n",
        "                        \"shape\": v[\"shape\"],\n",
        "                    }\n",
        "                    for v in state[\"variables\"]\n",
        "                ],\n",
        "                indent=4,\n",
        "            ),\n",
        "            parameters=json.dumps(\n",
        "                [\n",
        "                    {\n",
        "                        \"definition\": p[\"definition\"],\n",
        "                        \"symbol\": p[\"symbol\"],\n",
        "                        \"shape\": p[\"shape\"],\n",
        "                    }\n",
        "                    for p in state[\"parameters\"]\n",
        "                ],\n",
        "                indent=4,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        cnt = 3\n",
        "        while cnt > 0:\n",
        "            cnt -= 1\n",
        "            try:\n",
        "                response = self.llm_call(prompt=prompt, seed=cnt)\n",
        "                print(\"=\" * 10)\n",
        "                print(response)\n",
        "                print(\"=\" * 10)\n",
        "                output = response\n",
        "                # delete until the first '```json'\n",
        "                if \"```json\" in output:\n",
        "                    output = output[output.find(\"```json\") + 7 :]\n",
        "                    output = output[: output.rfind(\"```\")]\n",
        "\n",
        "                # go back until the last character is a }\n",
        "                while output[-1] != \"}\":\n",
        "                    output = output[:-1]\n",
        "\n",
        "                # go forward until the first character is a {\n",
        "                while output[0] != \"{\":\n",
        "                    output = output[1:]\n",
        "\n",
        "                # if there are '$' in the output, remove them\n",
        "                if \"$\" in output:\n",
        "                    output = output.replace(\"$\", \"\")\n",
        "\n",
        "                # find \"formulation\": \" in output\n",
        "                formulation_start = output.find('\"formulation\"')\n",
        "                # find \"new_variables\": \" in output\n",
        "                auxiliary_constraints_start = output.find('\"auxiliary_constraints\"')\n",
        "                # go back until you find a closed bracket\n",
        "                while output[auxiliary_constraints_start] != \"}\":\n",
        "                    auxiliary_constraints_start -= 1\n",
        "                while output[auxiliary_constraints_start] != '\"':\n",
        "                    auxiliary_constraints_start -= 1\n",
        "\n",
        "                # extract the formulation\n",
        "                formulation = output[\n",
        "                    formulation_start + 16 : auxiliary_constraints_start\n",
        "                ]\n",
        "                # remove it from the output\n",
        "                output = (\n",
        "                    output[: formulation_start + 16]\n",
        "                    + output[auxiliary_constraints_start:]\n",
        "                )\n",
        "\n",
        "                formulation = formulation.replace(\"\\\\\\\\\", \"\\\\\")\n",
        "                output = output.replace(\"\\\\\", \"\\\\\\\\\")\n",
        "                output = output.replace(\"\\\\\", \"\\\\\\\\\")\n",
        "                output = output.replace(\"\\\\\\\\quad\", \"\\\\\\\\\")\n",
        "\n",
        "                update = json.loads(output)\n",
        "                update[target_type][\"formulation\"] = formulation\n",
        "\n",
        "                # Extract related variables and parameters from the formulation\n",
        "                related_stuff = self.get_related_stuff(\n",
        "                    state, formulation, update[\"new_variables\"]\n",
        "                )\n",
        "                update[\"variables_mentioned\"] = related_stuff[\"variables_mentioned\"]\n",
        "                update[\"parameters_mentioned\"] = related_stuff[\"parameters_mentioned\"]\n",
        "\n",
        "                if not \"new_variables\" in update.keys():\n",
        "                    raise Exception(\"new_variables is not in the json file!\")\n",
        "                if not \"formulation\" in update[target_type].keys():\n",
        "                    raise Exception(\"formulation is not in the json file!\")\n",
        "                if not \"auxiliary_constraints\" in update.keys():\n",
        "                    update[\"auxiliary_constraints\"] = []\n",
        "\n",
        "                break\n",
        "            except Exception as e:\n",
        "                import traceback\n",
        "\n",
        "                print(traceback.format_exc())\n",
        "                print(\"=\" * 10)\n",
        "                print(e)\n",
        "                print(\"=\" * 10)\n",
        "                print(prompt)\n",
        "                print(\"=\" * 10)\n",
        "                print(response)\n",
        "                print(\"=\" * 10)\n",
        "                print(\n",
        "                    f\"Invalid json format in {target_type} formulation!\\n{e}\\n Try again ...\"\n",
        "                )\n",
        "\n",
        "        if cnt == 0:\n",
        "            raise Exception(\"Invalid json format!\")\n",
        "\n",
        "        all_variable_symbols = [variable[\"symbol\"] for variable in state[\"variables\"]]\n",
        "\n",
        "        for variable in update[\"new_variables\"]:\n",
        "            if variable[\"symbol\"] in all_variable_symbols:\n",
        "                # raise Exception(f\"Variable {variable['symbol']} already exists!\")\n",
        "                continue\n",
        "            else:\n",
        "                variable[\"status\"] = \"formulated\"\n",
        "                state[\"variables\"].append(variable)\n",
        "                if not variable[\"symbol\"] in update[\"variables_mentioned\"]:\n",
        "                    update[\"variables_mentioned\"].append(variable[\"symbol\"])\n",
        "\n",
        "        target[\"formulation\"] = update[target_type][\"formulation\"]\n",
        "        target[\"status\"] = \"formulated\"\n",
        "\n",
        "        target[\"related_variables\"] = update[\"variables_mentioned\"]\n",
        "        target[\"related_parameters\"] = update[\"parameters_mentioned\"]\n",
        "\n",
        "        # Add auxiliary constraints\n",
        "        if \"auxiliary_constraints\" in update.keys():\n",
        "            for constraint in update[\"auxiliary_constraints\"]:\n",
        "                constraint[\"status\"] = \"formulated\"\n",
        "\n",
        "                constraint[\"formulation\"] = (\n",
        "                    constraint[\"formulation\"]\n",
        "                    .replace(\"\\\\\\\\\", \"\\\\\")\n",
        "                    .replace(\"\\\\\\\\\", \"\\\\\")\n",
        "                )\n",
        "\n",
        "                # Extract related variables and parameters from the formulation\n",
        "                related_stuff = self.get_related_stuff(\n",
        "                    state, constraint[\"formulation\"], []\n",
        "                )\n",
        "                constraint[\"related_variables\"] = related_stuff[\"variables_mentioned\"]\n",
        "                constraint[\"related_parameters\"] = related_stuff[\"parameters_mentioned\"]\n",
        "\n",
        "                state[\"constraint\"].append(constraint)\n",
        "\n",
        "        print(f\"Formulation: {target['formulation']}\")\n",
        "        print(\"---\")\n",
        "        return\n",
        "\n",
        "    def _fix_available_formulation(self, target, target_type: str, state):\n",
        "        print(f\"Fixing {target_type} ...\")\n",
        "        context = {}\n",
        "        context[target_type] = {}\n",
        "        context[target_type][\"description\"] = target[\"description\"]\n",
        "\n",
        "        context[\"variables\"] = state[\"variables\"]\n",
        "        context[\"parameters\"] = state[\"parameters\"]\n",
        "        context[\"formulation\"] = target[\"formulation\"]\n",
        "        context[\"error\"] = state[\"error_message\"]\n",
        "\n",
        "        prompt = fix_prompt_template.format(\n",
        "            target=target_type,\n",
        "            constraint=json.dumps(context[target_type][\"description\"], indent=4),\n",
        "            variables=json.dumps(context[\"variables\"], indent=4),\n",
        "            parameters=json.dumps(context[\"parameters\"], indent=4),\n",
        "            formulation=json.dumps(context[\"formulation\"], indent=4),\n",
        "            json=json.dumps(target),\n",
        "            error=context[\"error\"],\n",
        "        )\n",
        "\n",
        "        cnt = 3\n",
        "        while cnt > 0:\n",
        "            cnt -= 1\n",
        "            try:\n",
        "                output = self.llm_call(prompt=prompt)\n",
        "                # delete until the first '```json'\n",
        "                output = output[output.find(\"```json\") + 7 :]\n",
        "                # delete until the last '```'\n",
        "                output = output[: output.rfind(\"```\")]\n",
        "\n",
        "                output = output.replace(\" \\\\\", \" \\\\\\\\\")\n",
        "                update = json.loads(output)\n",
        "\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                print(\n",
        "                    f\"Invalid json format in {target_type} formulation! Try again ...\"\n",
        "                )\n",
        "\n",
        "        if cnt == 0:\n",
        "            raise Exception(\"Invalid json format!\")\n",
        "\n",
        "        target[\"formulation\"] = update[\"formulation\"]\n",
        "        target[\"related_variables\"] = update[\"related_variables\"]\n",
        "        target[\"related_parameters\"] = update[\"related_parameters\"]\n",
        "        target[\"status\"] = \"formulated\"\n",
        "\n",
        "        return\n",
        "\n",
        "    def generate_reply(self, task: str, state: Dict, sender: Agent) -> (str, Dict):\n",
        "        # add some lines and characters around it to make the input interface nicer\n",
        "\n",
        "        print(\"- Formulator agent is called!\")\n",
        "        print()\n",
        "\n",
        "        self._formulate(\"constraint\", state)\n",
        "        self._formulate(\"objective\", state)\n",
        "\n",
        "        return \"Formulation Done! Now we can write the code.\", state\n",
        "\n",
        "    def get_related_stuff(self, state, formulation, new_variables):\n",
        "        ret = {}\n",
        "        ret[\"variables_mentioned\"] = []\n",
        "        ret[\"parameters_mentioned\"] = []\n",
        "\n",
        "        # find all symbols enclosed in \\textup{} in the formulation\n",
        "        symbols_mentioned = []\n",
        "        for i in range(len(formulation)):\n",
        "            if formulation[i : i + 8] == \"\\\\textup{\":\n",
        "                j = i + 8\n",
        "                while formulation[j] != \"}\":\n",
        "                    j += 1\n",
        "                symbols_mentioned.append(formulation[i + 8 : j])\n",
        "\n",
        "        all_parameter_symbols = [\n",
        "            parameter[\"symbol\"] for parameter in state[\"parameters\"]\n",
        "        ]\n",
        "        all_variable_symbols = [variable[\"symbol\"] for variable in state[\"variables\"]]\n",
        "        all_variable_symbols += [variable[\"symbol\"] for variable in new_variables]\n",
        "\n",
        "        # print(all_parameter_symbols)\n",
        "        # print(all_variable_symbols)\n",
        "\n",
        "        for symbol in symbols_mentioned:\n",
        "            if symbol in all_parameter_symbols:\n",
        "                ret[\"parameters_mentioned\"].append(symbol)\n",
        "            elif symbol in all_variable_symbols:\n",
        "                ret[\"variables_mentioned\"].append(symbol)\n",
        "            elif symbol.lower().strip() in [\n",
        "                \"min\",\n",
        "                \"max\",\n",
        "                \"subject to\",\n",
        "                \"s.t.\",\n",
        "                \"st\",\n",
        "                \"minimize\",\n",
        "                \"maximize\",\n",
        "                \"sum\",\n",
        "                \"for all\",\n",
        "                \"forall\",\n",
        "                \"such that\",\n",
        "                \"and\",\n",
        "                \"or\",\n",
        "                \"if\",\n",
        "                \"then\",\n",
        "                \"else\",\n",
        "                \"otherwise\",\n",
        "                \"for each\",\n",
        "                \"exists\",\n",
        "                \"foreach\",\n",
        "            ]:\n",
        "                continue\n",
        "            elif \" \" in symbol:\n",
        "                continue\n",
        "            else:\n",
        "                raise Exception(f\"Symbol {symbol} is not defined!\")\n",
        "\n",
        "        return ret"
      ],
      "metadata": {
        "id": "6Vc6Cl5MAJL_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install openai transformers\n",
        "\n",
        "# Import necessary modules\n",
        "from typing import Dict\n",
        "import json\n",
        "import openai\n",
        "from transformers import pipeline\n",
        "\n",
        "# Define the Agent class (from agent.py)\n",
        "class Agent:\n",
        "    def __init__(self, name, description, client, llm=\"gpt-3.5-turbo\", **kwargs):\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.client = client\n",
        "        self.system_prompt = \"You're a helpful assistant.\"\n",
        "        self.kwargs = kwargs\n",
        "        self.llm = llm\n",
        "\n",
        "    def llm_call(\n",
        "        self,\n",
        "        prompt: Optional[str] = None,\n",
        "        messages: Optional[List] = None,\n",
        "        seed: int = 10,\n",
        "    ) -> str:\n",
        "        model = self.llm\n",
        "        # make sure exactly one of prompt or messages is provided\n",
        "        assert (prompt is None) != (messages is None)\n",
        "        # make sure if messages is provided, it is a list of dicts with role and content\n",
        "        if messages is not None:\n",
        "            assert isinstance(messages, list)\n",
        "            for message in messages:\n",
        "                assert isinstance(message, dict)\n",
        "                assert \"role\" in message\n",
        "                assert \"content\" in message\n",
        "\n",
        "        if not prompt is None:\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ]\n",
        "\n",
        "        if type(self.client) in [OpenAI, Client]:\n",
        "            completion = self.client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=messages,\n",
        "                seed=seed,\n",
        "            )\n",
        "            content = completion.choices[0].message.content\n",
        "\n",
        "        elif type(self.client) == MistralClient:\n",
        "            messages = [\n",
        "                ChatMessage(role=message[\"role\"], content=message[\"content\"])\n",
        "                for message in messages\n",
        "            ]\n",
        "            completion = self.client.chat(\n",
        "                model=model,\n",
        "                messages=messages,\n",
        "            )\n",
        "            content = completion.choices[0].message.content\n",
        "\n",
        "        return content\n",
        "\n",
        "    def generate_reply(\n",
        "        self,\n",
        "        task: str,\n",
        "        state: Dict,\n",
        "        sender: \"Agent\",\n",
        "    ) -> Tuple[str, Dict]:\n",
        "        return (\n",
        "            \"This is a reply from the agent. REPLY NOT IMPLEMENTED! Terminate the whole process!\",\n",
        "            state,\n",
        "        )\n",
        "\n",
        "# Define the Formulator class (from formulator.py)\n",
        "fix_prompt_template = \"\"\"\n",
        "You are a mathematical formulator working with a team of optimization experts. The objective is to tackle a complex optimization problem, and your role is to fix a previously modelled {target}.\n",
        "\n",
        "Recall that the {target} you modelled was\n",
        "\n",
        "-----\n",
        "{constraint}\n",
        "-----\n",
        "\n",
        "and your formulation you provided was\n",
        "\n",
        "-----\n",
        "{formulation}\n",
        "-----\n",
        "\n",
        "The error message is\n",
        "\n",
        "-----\n",
        "{error}\n",
        "-----\n",
        "\n",
        "Here are the variables you have so far defined:\n",
        "\n",
        "-----\n",
        "{variables}\n",
        "-----\n",
        "\n",
        "Here are the parameters of the problem\n",
        "\n",
        "-----\n",
        "{parameters}\n",
        "-----\n",
        "\n",
        "Your task is carefully inspect the old {target} and fix it when you find it actually wrong.\n",
        "After fixing it modify the formulation. Please return the fixed JSON string for the formulation.\n",
        "\n",
        "The current JSON is\n",
        "\n",
        "-----\n",
        "{json}\n",
        "-----\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "You are an expert mathematical formulator and an optimization professor at a top university. Your task is to model {targetType} of the problem in the standard LP or MILP form.\n",
        "\n",
        "Here is a {targetType} we need you to model:\n",
        "-----\n",
        "{targetDescription}\n",
        "-----\n",
        "\n",
        "Here is some context on the problem:\n",
        "-----\n",
        "{background}\n",
        "-----\n",
        "\n",
        "Here is the list of available variables:\n",
        "-----\n",
        "{variables}\n",
        "-----\n",
        "\n",
        "And finally, here is list of input parameters:\n",
        "-----\n",
        "{parameters}\n",
        "-----\n",
        "\n",
        "First, take a deep breath and explain how we should define the {targetType}. Feel free to define new variables if you think it is necessary. Then, generate a json file accordingly with the following format (STICK TO THIS FORMAT!):\n",
        "\n",
        "\n",
        "{{\n",
        "    \"{targetType}\": {{\n",
        "      \"description\": \"The description of the {targetType}\",\n",
        "      \"formulation\": \"The LaTeX mathematical expression representing the formulation of the {targetType}\"\n",
        "    }},\n",
        "    \"auxiliary_constraints\": [\n",
        "        {{\n",
        "            \"description\": \"The description of the auxiliary constraint\",\n",
        "            \"formulation\": \"The LaTeX mathematical expression representing the formulation of the auxiliary constraint\"\n",
        "        }}\n",
        "    ]\n",
        "    \"new_variables\": [\n",
        "        {{\n",
        "            \"definition\": \"The definition of the variable\",\n",
        "            \"symbol\": \"The symbol for the variable\",\n",
        "            \"shape\": [ \"symbol1\", \"symbol2\", ... ]\n",
        "        }}\n",
        "    ],\n",
        "\n",
        "}}\n",
        "\n",
        "- Your formulation should be in LaTeX mathematical format (do not include the $ symbols).\n",
        "- Note that I'm going to use python json.loads() function to parse the json file, so please make sure the format is correct (don't add ',' before enclosing '}}' or ']' characters.\n",
        "- Generate the complete json file and don't omit anything.\n",
        "- Use '```json' and '```' to enclose the json file.\n",
        "- Important: You can not define new parameters. You can only define new variables.Use CamelCase and full words for new variable symbols, and do not include indices in the symbol (e.g. ItemsSold instead of itemsSold or items_sold or ItemsSold_i)\n",
        "- Use \\\\textup{{}} when writing variable and parameter names. For example (\\\\sum_{{i=1}}^{{N}} \\\\textup{{ItemsSold}}_{{i}} instead of \\\\sum_{{i=1}}^{{N}} ItemsSold_{{i}})\n",
        "- Use \\\\quad for spaces.\n",
        "- Use empty list ([]) if no new variables are defined.\n",
        "- Always use non-strict inequalities (e.g. \\\\leq instead of <), even if the constraint is strict.\n",
        "- Define auxiliary constraints when necessary. Set it to an empty list ([]) if no auxiliary constraints are needed. If new auxiliary constraints need new variables, add them to the \"new_variables\" list too.\n",
        "\n",
        "Take a deep breath and solve the problem step by step.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Formulator(Agent):\n",
        "    def __init__(self, client=None, **kwargs):\n",
        "        super().__init__(\n",
        "            name=\"Formulator\",\n",
        "            description=\"This is a mathematical formulator agent that is an expert in mathematical and optimization modeling and can define and modify variables, constraints, and objective functions. Does 3 things: 1) Defining constraints, variables, and objective functions, 2) Modifying constraints, variables, and objective functions, 3) Other things related to mathematical formulation. If the history is empty, start from this agent.\",\n",
        "            client=client,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.llm = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "    def _formulate(self, target_type: str, state):\n",
        "        for target in state[target_type]:\n",
        "            if target[\"status\"] == \"not_formulated\":\n",
        "                self._create_new_formulation(target, target_type, state)\n",
        "            elif target[\"status\"] == \"runtime_error\":\n",
        "                self._fix_available_formulation(target, target_type, state)\n",
        "            elif target[\"status\"] == \"formulated\":\n",
        "                continue\n",
        "            else:\n",
        "                error_msg = f\"Invalid status: {json.dumps(target, indent=4)}\"\n",
        "                raise RuntimeError(error_msg)\n",
        "\n",
        "        return\n",
        "\n",
        "    def _create_new_formulation(self, target, target_type: str, state):\n",
        "        print(f\"Formulating {target_type} ...\")\n",
        "        context = {}\n",
        "        context[target_type] = {}\n",
        "        prompt = prompt_template.format(\n",
        "            background=state[\"background\"],\n",
        "            targetType=target_type,\n",
        "            targetDescription=target[\"description\"],\n",
        "            variables=json.dumps(\n",
        "                [\n",
        "                    {\n",
        "                        \"definition\": v[\"definition\"],\n",
        "                        \"symbol\": v[\"symbol\"],\n",
        "                        \"shape\": v[\"shape\"],\n",
        "                    }\n",
        "                    for v in state[\"variables\"]\n",
        "                ],\n",
        "                indent=4,\n",
        "            ),\n",
        "            parameters=json.dumps(\n",
        "                [\n",
        "                    {\n",
        "                        \"definition\": p[\"definition\"],\n",
        "                        \"symbol\": p[\"symbol\"],\n",
        "                        \"shape\": p[\"shape\"],\n",
        "                    }\n",
        "                    for p in state[\"parameters\"]\n",
        "                ],\n",
        "                indent=4,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        cnt = 3\n",
        "        while cnt > 0:\n",
        "            cnt -= 1\n",
        "            try:\n",
        "                response = self.llm(prompt, max_length=1024, num_return_sequences=1)[0]['generated_text']\n",
        "                print(\"=\" * 10)\n",
        "                print(response)\n",
        "                print(\"=\" * 10)\n",
        "                output = response\n",
        "                # delete until the first '```json'\n",
        "                if \"```json\" in output:\n",
        "                    output = output[output.find(\"```json\") + 7 :]\n",
        "                    output = output[: output.rfind(\"```\")]\n",
        "\n",
        "                # go back until the last character is a }\n",
        "                while output[-1] != \"}\":\n",
        "                    output = output[:-1]\n",
        "\n",
        "                # go forward until the first character is a {\n",
        "                while output[0] != \"{\":\n",
        "                    output = output[1:]\n",
        "\n",
        "                # if there are '$' in the output, remove them\n",
        "                if \"$\" in output:\n",
        "                    output = output.replace(\"$\", \"\")\n",
        "\n",
        "                # find \"formulation\": \" in output\n",
        "                formulation_start = output.find('\"formulation\"')\n",
        "                # find \"new_variables\": \" in output\n",
        "                auxiliary_constraints_start = output.find('\"auxiliary_constraints\"')\n",
        "                # go back until you find a closed bracket\n",
        "                while output[auxiliary_constraints_start] != \"}\":\n",
        "                    auxiliary_constraints_start -= 1\n",
        "                while output[auxiliary_constraints_start] != '\"':\n",
        "                    auxiliary_constraints_start -= 1\n",
        "\n",
        "                # extract the formulation\n",
        "                formulation = output[\n",
        "                    formulation_start + 16 : auxiliary_constraints_start\n",
        "                ]\n",
        "                # remove it from the output\n",
        "                output = (\n",
        "                    output[: formulation_start + 16]\n",
        "                    + output[auxiliary_constraints_start:]\n",
        "                )\n",
        "\n",
        "                formulation = formulation.replace(\"\\\\\\\\\", \"\\\\\")\n",
        "                output = output.replace(\"\\\\\", \"\\\\\\\\\")\n",
        "                output = output.replace(\"\\\\\", \"\\\\\\\\\")\n",
        "                output = output.replace(\"\\\\\\\\quad\", \"\\\\\\\\\")\n",
        "\n",
        "                update = json.loads(output)\n",
        "                update[target_type][\"formulation\"] = formulation\n",
        "\n",
        "                # Extract related variables and parameters from the formulation\n",
        "                related_stuff = self.get_related_stuff(\n",
        "                    state, formulation, update[\"new_variables\"]\n",
        "                )\n",
        "                update[\"variables_mentioned\"] = related_stuff[\"variables_mentioned\"]\n",
        "                update[\"parameters_mentioned\"] = related_stuff[\"parameters_mentioned\"]\n",
        "\n",
        "                if not \"new_variables\" in update.keys():\n",
        "                    raise Exception(\"new_variables is not in the json file!\")\n",
        "                if not \"formulation\" in update[target_type].keys():\n",
        "                    raise Exception(\"formulation is not in the json file!\")\n",
        "                if not \"auxiliary_constraints\" in update.keys():\n",
        "                    update[\"auxiliary_constraints\"] = []\n",
        "\n",
        "                break\n",
        "            except Exception as e:\n",
        "                import traceback\n",
        "\n",
        "                print(traceback.format_exc())\n",
        "                print(\"=\" * 10)\n",
        "                print(e)\n",
        "                print(\"=\" * 10)\n",
        "                print(prompt)\n",
        "                print(\"=\" * 10)\n",
        "                print(response)\n",
        "                print(\"=\" * 10)\n",
        "                print(\n",
        "                    f\"Invalid json format in {target_type} formulation!\\n{e}\\n Try again ...\"\n",
        "                )\n",
        "\n",
        "        if cnt == 0:\n",
        "            raise Exception(\"Invalid json format!\")\n",
        "\n",
        "        all_variable_symbols = [variable[\"symbol\"] for variable in state[\"variables\"]]\n",
        "\n",
        "        for variable in update[\"new_variables\"]:\n",
        "            if variable[\"symbol\"] in all_variable_symbols:\n",
        "                # raise Exception(f\"Variable {variable['symbol']} already exists!\")\n",
        "                continue\n",
        "            else:\n",
        "                variable[\"status\"] = \"formulated\"\n",
        "                state[\"variables\"].append(variable)\n",
        "                if not variable[\"symbol\"] in update[\"variables_mentioned\"]:\n",
        "                    update[\"variables_mentioned\"].append(variable[\"symbol\"])\n",
        "\n",
        "        target[\"formulation\"] = update[target_type][\"formulation\"]\n",
        "        target[\"status\"] = \"formulated\"\n",
        "\n",
        "        target[\"related_variables\"] = update[\"variables_mentioned\"]\n",
        "        target[\"related_parameters\"] = update[\"parameters_mentioned\"]\n",
        "\n",
        "        # Add auxiliary constraints\n",
        "        if \"auxiliary_constraints\" in update.keys():\n",
        "            for constraint in update[\"auxiliary_constraints\"]:\n",
        "                constraint[\"status\"] = \"formulated\"\n",
        "\n",
        "                constraint[\"formulation\"] = (\n",
        "                    constraint[\"formulation\"]\n",
        "                    .replace(\"\\\\\\\\\", \"\\\\\")\n",
        "                    .replace(\"\\\\\\\\\", \"\\\\\")\n",
        "                )\n",
        "\n",
        "                # Extract related variables and parameters from the formulation\n",
        "                related_stuff = self.get_related_stuff(\n",
        "                    state, constraint[\"formulation\"], []\n",
        "                )\n",
        "                constraint[\"related_variables\"] = related_stuff[\"variables_mentioned\"]\n",
        "                constraint[\"related_parameters\"] = related_stuff[\"parameters_mentioned\"]\n",
        "\n",
        "                state[\"constraint\"].append(constraint)\n",
        "\n",
        "        print(f\"Formulation: {target['formulation']}\")\n",
        "        print(\"---\")\n",
        "        return\n",
        "\n",
        "    def _fix_available_formulation(self, target, target_type: str, state):\n",
        "        print(f\"Fixing {target_type} ...\")\n",
        "        context = {}\n",
        "        context[target_type] = {}\n",
        "        context[target_type][\"description\"] = target[\"description\"]\n",
        "\n",
        "        context[\"variables\"] = state[\"variables\"]\n",
        "        context[\"parameters\"] = state[\"parameters\"]\n",
        "        context[\"formulation\"] = target[\"formulation\"]\n",
        "        context[\"error\"] = state[\"error_message\"]\n",
        "\n",
        "        prompt = fix_prompt_template.format(\n",
        "            target=target_type,\n",
        "            constraint=json.dumps(context[target_type][\"description\"], indent=4),\n",
        "            variables=json.dumps(context[\"variables\"], indent=4),\n",
        "            parameters=json.dumps(context[\"parameters\"], indent=4),\n",
        "            formulation=json.dumps(context[\"formulation\"], indent=4),\n",
        "            json=json.dumps(target),\n",
        "            error=context[\"error\"],\n",
        "        )\n",
        "\n",
        "        cnt = 3\n",
        "        while cnt > 0:\n",
        "            cnt -= 1\n",
        "            try:\n",
        "                response = self.llm(prompt, max_length=1024, num_return_sequences=1)[0]['generated_text']\n",
        "                # delete until the first '```json'\n",
        "                output = response[response.find(\"```json\") + 7 :]\n",
        "                # delete until the last '```'\n",
        "                output = output[: output.rfind(\"```\")]\n",
        "\n",
        "                output = output.replace(\" \\\\\", \" \\\\\\\\\")\n",
        "                update = json.loads(output)\n",
        "\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                print(\n",
        "                    f\"Invalid json format in {target_type} formulation! Try again ...\"\n",
        "                )\n",
        "\n",
        "        if cnt == 0:\n",
        "            raise Exception(\"Invalid json format!\")\n",
        "\n",
        "        target[\"formulation\"] = update[\"formulation\"]\n",
        "        target[\"related_variables\"] = update[\"related_variables\"]\n",
        "        target[\"related_parameters\"] = update[\"related_parameters\"]\n",
        "        target[\"status\"] = \"formulated\"\n",
        "\n",
        "        return\n",
        "\n",
        "    def generate_reply(self, task: str, state: Dict, sender: Agent) -> Tuple[str, Dict]:\n",
        "        # add some lines and characters around it to make the input interface nicer\n",
        "\n",
        "        print(\"- Formulator agent is called!\")\n",
        "        print()\n",
        "\n",
        "        self._formulate(\"constraint\", state)\n",
        "        self._formulate(\"objective\", state)\n",
        "\n",
        "        return \"Formulation Done! Now we can write the code.\", state\n",
        "\n",
        "    def get_related_stuff(self, state, formulation, new_variables):\n",
        "        ret = {}\n",
        "        ret[\"variables_mentioned\"] = []\n",
        "        ret[\"parameters_mentioned\"] = []\n",
        "\n",
        "        # find all symbols enclosed in \\textup{} in the formulation\n",
        "        symbols_mentioned = []\n",
        "        for i in range(len(formulation)):\n",
        "            if formulation[i : i + 8] == \"\\\\textup{\":\n",
        "                j = i + 8\n",
        "                while formulation[j] != \"}\":\n",
        "                    j += 1\n",
        "                symbols_mentioned.append(formulation[i + 8 : j])\n",
        "\n",
        "        all_parameter_symbols = [\n",
        "            parameter[\"symbol\"] for parameter in state[\"parameters\"]\n",
        "        ]\n",
        "        all_variable_symbols = [variable[\"symbol\"] for variable in state[\"variables\"]]\n",
        "        all_variable_symbols += [variable[\"symbol\"] for variable in new_variables]\n",
        "\n",
        "        # print(all_parameter_symbols)\n",
        "        # print(all_variable_symbols)\n",
        "\n",
        "        for symbol in symbols_mentioned:\n",
        "            if symbol in all_parameter_symbols:\n",
        "                ret[\"parameters_mentioned\"].append(symbol)\n",
        "            elif symbol in all_variable_symbols:\n",
        "                ret[\"variables_mentioned\"].append(symbol)\n",
        "            elif symbol.lower().strip() in [\n",
        "                \"min\",\n",
        "                \"max\",\n",
        "                \"subject to\",\n",
        "                \"s.t.\",\n",
        "                \"st\",\n",
        "                \"minimize\",\n",
        "                \"maximize\",\n",
        "                \"sum\",\n",
        "                \"for all\",\n",
        "                \"forall\",\n",
        "                \"such that\",\n",
        "                \"and\",\n",
        "                \"or\",\n",
        "                \"if\",\n",
        "                \"then\",\n",
        "                \"else\",\n",
        "                \"otherwise\",\n",
        "                \"for each\",\n",
        "                \"exists\",\n",
        "                \"foreach\",\n",
        "            ]:\n",
        "                continue\n",
        "            elif \" \" in symbol:\n",
        "                continue\n",
        "            else:\n",
        "                raise Exception(f\"Symbol {symbol} is not defined!\")\n",
        "\n",
        "        return ret\n",
        "\n",
        "# Define the GroupChatManager class (from manager.py)\n",
        "class GroupChatManager(Agent):\n",
        "    def __init__(\n",
        "        self, client: openai.Client, agents: List[Agent], max_rounds: int = 12, **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            name=\"GroupChatManager\",\n",
        "            description=\"This is a manager agent that chooses which agent to work on the problem next and organizes the conversation within its team.\",\n",
        "            client=client,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        self.agents = agents\n",
        "        self.conversation_state = {\n",
        "            \"round\": 0,\n",
        "        }\n",
        "        self.max_rounds = max_rounds\n",
        "        self.history = []\n",
        "        self.prompt_template = \"\"\"\n",
        "\n",
        "You're a manager in a team of optimization experts. The goal of the team is to solve an optimization problem. Your task is to choose the next expert to work on the problem based on the current situation.\n",
        "- The user has already given us the problem description, the objective function, and the parameters. Only call the user proxy if there is a problem or something ambiguous or missing.\n",
        "\n",
        "Here's the list of agents in your team:\n",
        "-----\n",
        "{agents}\n",
        "-----\n",
        "\n",
        "And here's the history of the conversation so far:\n",
        "-----\n",
        "{history}\n",
        "-----\n",
        "\n",
        "\n",
        "Considering the history, if you think the problem is solved, type DONE. Otherwise, generate a json file with the following format:\n",
        "{{\n",
        "    \"agent_name\": \"Name of the agent you want to call next\",\n",
        "    \"task\": \"The task you want the agent to carry out\"\n",
        "}}\n",
        "\n",
        "to identify the next agent to work on the problem, and also the task it has to carry out.\n",
        "- If there is a runtime error, ask the the prorammer agent to fix it.\n",
        "- Only generate the json file, and don't generate any other text.\n",
        "- If the latest message in history says that the code is fixed, ask the evaluator agent to evaluate the code!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    def solve(self, state: Dict) -> Tuple[str, Dict]:\n",
        "      self.history = []\n",
        "\n",
        "      while True:\n",
        "        if self.conversation_state[\"round\"] >= self.max_rounds:\n",
        "            return \"The problem is not solved.\", state\n",
        "\n",
        "        print(\"=\" * 20)\n",
        "        print(\"=\" * 20)\n",
        "        print(\"Round\", self.conversation_state[\"round\"])\n",
        "        # print(json.dumps(state, indent=4))\n",
        "\n",
        "        agents_list = \"\".join(\n",
        "            [\n",
        "                \"-\" + agent.name + \": \" + agent.description + \"\\n\"\n",
        "                for agent in self.agents\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        prompt = self.prompt_template.format(\n",
        "            agents=agents_list,\n",
        "            history=\"\\n\".join([json.dumps(item[0]) for item in self.history]),\n",
        "        )\n",
        "\n",
        "        cnt = 3\n",
        "        while True and cnt > 0:\n",
        "            try:\n",
        "                response = self.llm_call(prompt=prompt, seed=cnt)\n",
        "\n",
        "                decision = response.strip()\n",
        "                if \"```json\" in decision:\n",
        "                    decision = decision.split(\"```json\")[1].split(\"```\")[0]\n",
        "                decision = decision.replace(\"\\\\\", \"\")\n",
        "\n",
        "                if decision == \"DONE\":\n",
        "                    print(\"DONE\")\n",
        "                    return \"The problem is solved.\", state\n",
        "                decision = json.loads(decision)\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(response)\n",
        "                print(e)\n",
        "                cnt -= 1\n",
        "\n",
        "                print(\"Invalid decision. Trying again ...\")\n",
        "                if cnt == 0:\n",
        "                    import traceback\n",
        "\n",
        "                    err = traceback.format_exc()\n",
        "                    print(err)\n",
        "\n",
        "        print(\n",
        "            \"---- History:\\n\",\n",
        "            \"\\n\".join([json.dumps(item[0]) for item in self.history]),\n",
        "        )\n",
        "\n",
        "        print(f\"\\n---- Decision:||{decision}||\\n\")\n",
        "\n",
        "        # wait for the user to press enter\n",
        "        # input()\n",
        "\n",
        "        if not decision[\"agent_name\"] in [agent.name for agent in self.agents]:\n",
        "            raise ValueError(\n",
        "                f\"Decision {decision} is not a valid agent name. Please choose from {self.agents}\"\n",
        "            )\n",
        "        else:\n",
        "            agent = [\n",
        "                agent\n",
        "                for agent in self.agents\n",
        "                if agent.name == decision[\"agent_name\"]\n",
        "            ][0]\n",
        "\n",
        "            message, new_state = agent.generate_reply(\n",
        "                task=decision[\"task\"],\n",
        "                state=state,\n",
        "                sender=self,\n",
        "            )\n",
        "\n",
        "            with open(\n",
        "                f\"{state['log_folder']}/log_{self.conversation_state['round']}.json\",\n",
        "                \"w\",\n",
        "            ) as f:\n",
        "                json.dump(state, f, indent=4)\n",
        "\n",
        "            state = new_state\n",
        "\n",
        "            decision[\"result\"] = message\n",
        "            self.history.append((decision, state))\n",
        "\n",
        "            with open(state[\"log_folder\"] + \"/selection_log.json\", \"w\") as f:\n",
        "                json.dump([d for (d, s) in self.history], f, indent=4)\n",
        "\n",
        "            if \"code\" in state:\n",
        "                with open(state[\"log_folder\"] + \"/code.py\", \"w\") as f:\n",
        "                    f.write(state[\"code\"])\n",
        "\n",
        "            self.conversation_state[\"round\"] += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWqzou4Tem89",
        "outputId": "94352abd-a4bd-475d-a396-5dddf4d711e2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.34.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n"
          ]
        }
      ]
    }
  ]
}